{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94047bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79cdeb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '01', '04', '05', '06', '08', '09', '11', '12', '13', '14', '15', '16', '18', '19', '20', '21', '23', '24', '26', '28', '29', '30', '31', '33', '35', '37', '38', '41', '42', '43', '44', '45', '50', '51', '53', '54', '56', '59', '60', '62', '63', '65', '69', '70', '72', '74', '75', '76', '77', '79', '81', '82', '84', '85', '87', '88', '89', '90', '91', '94', '95', '97', '98']\n",
      "Dataset CustomImageFolder\n",
      "    Number of datapoints: 64000\n",
      "    Root location: double_mnist/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Grayscale(num_output_channels=1)\n",
      "               Resize(size=(28, 28), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5,), std=(0.5,))\n",
      "           )\n",
      "['03', '07', '10', '22', '27', '34', '39', '40', '48', '52', '58', '61', '64', '71', '93', '99']\n",
      "tensor([18, 18, 85, 87, 62, 29, 16,  6, 95, 91, 30, 51, 43, 31,  6, 13, 56, 51,\n",
      "        60, 29,  6,  0, 60, 29, 97, 33, 62, 45, 26,  1, 81, 12, 85,  1, 95, 21,\n",
      "        81, 19,  5, 65, 38, 37,  1, 94, 54, 15, 89,  0, 44, 87, 59,  1, 42, 51,\n",
      "        33, 35, 30, 50, 28, 69, 56, 81, 84, 51])\n",
      "tensor(3)\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale if not already\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_data_path = 'double_mnist/train'\n",
    "val_data_path = 'double_mnist/val'\n",
    "test_data_path = 'double_mnist/test'\n",
    "class CustomImageFolder(ImageFolder):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super(CustomImageFolder, self).__init__(root, transform=transform)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        # Assign labels based on folder name\n",
    "        folder_name = os.path.basename(os.path.dirname(path))\n",
    "        return sample, int(folder_name)  # Convert the folder name to an integer label\n",
    "# Create ImageFolder datasets for training, validation, and test sets\n",
    "train_dataset = CustomImageFolder(train_data_path, transform=transform)\n",
    "val_dataset = CustomImageFolder(val_data_path, transform=transform)\n",
    "test_dataset = CustomImageFolder(test_data_path, transform=transform)\n",
    "print(train_dataset.classes)\n",
    "class_to_label = {str(i).zfill(2): i for i in range(100)}\n",
    "# Define batch sizes\n",
    "batch_size = 64\n",
    "print(train_dataset)\n",
    "# Create DataLoader instances for training, validation, and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 10\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "class_names = val_dataset.classes\n",
    "\n",
    "print(class_names)\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print(labels)\n",
    "    break\n",
    "for images, labels in val_loader:\n",
    "    plt.imshow(images[0].permute(1, 2, 0))\n",
    "    print(labels[0])\n",
    "    print(labels)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2471806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleMLP(nn.Module):\n",
    "#     def __init__(self, input_size, num_classes, hidden_size=128, dropout_rate=0.5):\n",
    "#         super(SimpleMLP, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.view(x.size(0), -1)  # Flatten the input\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# # Define the model\n",
    "# input_size = 28 * 28  # Replace with the actual input size\n",
    "# num_classes = 10  # Replace with the actual number of classes\n",
    "# hidden_size = 128\n",
    "# dropout_rate = 0.5\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, hidden_layers, hidden_neurons, dropout_rate=0.5):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_size, hidden_neurons[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "        for i in range(1, hidden_layers):\n",
    "            layers.append(nn.Linear(hidden_neurons[i-1], hidden_neurons[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.hidden = nn.Sequential(*layers)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc_out = nn.Linear(hidden_neurons[-1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        x = self.hidden(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_size = 28 * 28\n",
    "num_classes = 10\n",
    "hidden_layers = 3\n",
    "hidden_neurons = [256,256,256]  # Modify this list as needed\n",
    "dropout_rate = 0.5\n",
    "\n",
    "\n",
    "model = SimpleMLP(input_size, num_classes, hidden_layers, hidden_neurons, dropout_rate)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model1 = SimpleMLP(input_size, num_classes, hidden_layers, hidden_neurons, dropout_rate)\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c3909ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Train Loss: 1.9690 - Train Accuracy: 29.12%\n",
      "Epoch 1/25 - Validation Loss: 1.9367 - Validation Accuracy: 32.68%\n",
      "Epoch 1/25 - Testing Loss: 1.9647 - Testing Accuracy: 22.71%\n",
      "Epoch 2/25 - Train Loss: 1.7751 - Train Accuracy: 38.38%\n",
      "Epoch 2/25 - Validation Loss: 1.7664 - Validation Accuracy: 38.00%\n",
      "Epoch 2/25 - Testing Loss: 1.8324 - Testing Accuracy: 27.10%\n",
      "Epoch 3/25 - Train Loss: 1.6701 - Train Accuracy: 43.74%\n",
      "Epoch 3/25 - Validation Loss: 1.6841 - Validation Accuracy: 43.07%\n",
      "Epoch 3/25 - Testing Loss: 1.7891 - Testing Accuracy: 31.87%\n",
      "Epoch 4/25 - Train Loss: 1.5503 - Train Accuracy: 47.49%\n",
      "Epoch 4/25 - Validation Loss: 1.4802 - Validation Accuracy: 48.10%\n",
      "Epoch 4/25 - Testing Loss: 1.5961 - Testing Accuracy: 37.47%\n",
      "Epoch 5/25 - Train Loss: 1.4497 - Train Accuracy: 51.95%\n",
      "Epoch 5/25 - Validation Loss: 1.4572 - Validation Accuracy: 48.67%\n",
      "Epoch 5/25 - Testing Loss: 1.5138 - Testing Accuracy: 40.95%\n",
      "Epoch 6/25 - Train Loss: 1.3934 - Train Accuracy: 55.59%\n",
      "Epoch 6/25 - Validation Loss: 1.3352 - Validation Accuracy: 57.17%\n",
      "Epoch 6/25 - Testing Loss: 1.4182 - Testing Accuracy: 49.75%\n",
      "Epoch 7/25 - Train Loss: 1.3405 - Train Accuracy: 58.22%\n",
      "Epoch 7/25 - Validation Loss: 1.3019 - Validation Accuracy: 56.53%\n",
      "Epoch 7/25 - Testing Loss: 1.3486 - Testing Accuracy: 51.60%\n",
      "Epoch 8/25 - Train Loss: 1.3020 - Train Accuracy: 60.13%\n",
      "Epoch 8/25 - Validation Loss: 1.2345 - Validation Accuracy: 60.84%\n",
      "Epoch 8/25 - Testing Loss: 1.2719 - Testing Accuracy: 55.93%\n",
      "Epoch 9/25 - Train Loss: 1.2704 - Train Accuracy: 61.65%\n",
      "Epoch 9/25 - Validation Loss: 1.2182 - Validation Accuracy: 63.37%\n",
      "Epoch 9/25 - Testing Loss: 1.2385 - Testing Accuracy: 58.87%\n",
      "Epoch 10/25 - Train Loss: 1.2459 - Train Accuracy: 62.63%\n",
      "Epoch 10/25 - Validation Loss: 1.1688 - Validation Accuracy: 63.83%\n",
      "Epoch 10/25 - Testing Loss: 1.2808 - Testing Accuracy: 58.37%\n",
      "Epoch 11/25 - Train Loss: 1.2278 - Train Accuracy: 63.49%\n",
      "Epoch 11/25 - Validation Loss: 1.1690 - Validation Accuracy: 63.99%\n",
      "Epoch 11/25 - Testing Loss: 1.1831 - Testing Accuracy: 61.76%\n",
      "Epoch 12/25 - Train Loss: 1.2037 - Train Accuracy: 64.50%\n",
      "Epoch 12/25 - Validation Loss: 1.1448 - Validation Accuracy: 65.45%\n",
      "Epoch 12/25 - Testing Loss: 1.1624 - Testing Accuracy: 62.38%\n",
      "Epoch 13/25 - Train Loss: 1.1814 - Train Accuracy: 65.20%\n",
      "Epoch 13/25 - Validation Loss: 1.1259 - Validation Accuracy: 64.60%\n",
      "Epoch 13/25 - Testing Loss: 1.1871 - Testing Accuracy: 59.64%\n",
      "Epoch 14/25 - Train Loss: 1.1668 - Train Accuracy: 65.79%\n",
      "Epoch 14/25 - Validation Loss: 1.0945 - Validation Accuracy: 67.22%\n",
      "Epoch 14/25 - Testing Loss: 1.1082 - Testing Accuracy: 64.41%\n",
      "Epoch 15/25 - Train Loss: 1.1564 - Train Accuracy: 66.41%\n",
      "Epoch 15/25 - Validation Loss: 1.0843 - Validation Accuracy: 65.67%\n",
      "Epoch 15/25 - Testing Loss: 1.1682 - Testing Accuracy: 62.78%\n",
      "Epoch 16/25 - Train Loss: 1.1351 - Train Accuracy: 66.98%\n",
      "Epoch 16/25 - Validation Loss: 1.0534 - Validation Accuracy: 67.58%\n",
      "Epoch 16/25 - Testing Loss: 1.0984 - Testing Accuracy: 64.39%\n",
      "Epoch 17/25 - Train Loss: 1.1293 - Train Accuracy: 67.35%\n",
      "Epoch 17/25 - Validation Loss: 1.0347 - Validation Accuracy: 70.28%\n",
      "Epoch 17/25 - Testing Loss: 1.0495 - Testing Accuracy: 66.82%\n",
      "Epoch 18/25 - Train Loss: 1.1172 - Train Accuracy: 67.69%\n",
      "Epoch 18/25 - Validation Loss: 1.0600 - Validation Accuracy: 66.98%\n",
      "Epoch 18/25 - Testing Loss: 1.0854 - Testing Accuracy: 63.46%\n",
      "Epoch 19/25 - Train Loss: 1.1029 - Train Accuracy: 68.26%\n",
      "Epoch 19/25 - Validation Loss: 1.0046 - Validation Accuracy: 68.30%\n",
      "Epoch 19/25 - Testing Loss: 1.0852 - Testing Accuracy: 64.17%\n",
      "Epoch 20/25 - Train Loss: 1.0898 - Train Accuracy: 68.65%\n",
      "Epoch 20/25 - Validation Loss: 0.9762 - Validation Accuracy: 71.07%\n",
      "Epoch 20/25 - Testing Loss: 1.0061 - Testing Accuracy: 67.19%\n",
      "Epoch 21/25 - Train Loss: 1.0787 - Train Accuracy: 68.93%\n",
      "Epoch 21/25 - Validation Loss: 0.9533 - Validation Accuracy: 70.58%\n",
      "Epoch 21/25 - Testing Loss: 0.9742 - Testing Accuracy: 68.29%\n",
      "Epoch 22/25 - Train Loss: 1.0712 - Train Accuracy: 69.27%\n",
      "Epoch 22/25 - Validation Loss: 1.0268 - Validation Accuracy: 69.91%\n",
      "Epoch 22/25 - Testing Loss: 1.0326 - Testing Accuracy: 67.23%\n",
      "Epoch 23/25 - Train Loss: 1.0557 - Train Accuracy: 69.87%\n",
      "Epoch 23/25 - Validation Loss: 0.9559 - Validation Accuracy: 71.05%\n",
      "Epoch 23/25 - Testing Loss: 0.9949 - Testing Accuracy: 67.73%\n",
      "Epoch 24/25 - Train Loss: 1.0451 - Train Accuracy: 70.12%\n",
      "Epoch 24/25 - Validation Loss: 0.9200 - Validation Accuracy: 73.37%\n",
      "Epoch 24/25 - Testing Loss: 0.9508 - Testing Accuracy: 70.29%\n",
      "Epoch 25/25 - Train Loss: 1.0403 - Train Accuracy: 70.43%\n",
      "Epoch 25/25 - Validation Loss: 1.0144 - Validation Accuracy: 71.74%\n",
      "Epoch 25/25 - Testing Loss: 1.0434 - Testing Accuracy: 67.65%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    cnt = 0\n",
    "    for images, labels in train_loader:\n",
    "        labels1 = labels//10\n",
    "        labels2 = labels%10\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        image = images.clone()\n",
    "        image1 = images.clone()\n",
    "        left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "        image[:, :, :, (image.shape[3] // 2):] = left_half\n",
    "        right_half = images[:, :, :, images.shape[3] // 2 :]\n",
    "        image1[:, :, :, :(image1.shape[3] // 2)] = right_half\n",
    "        outputs = model(image)\n",
    "        outputs1 = model1(image1)\n",
    "        loss = criterion(outputs, labels1)\n",
    "        loss1 = criterion1(outputs1,labels2)\n",
    "        loss.backward()\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "        optimizer1.step()\n",
    "        total_train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, predicted1 = torch.max(outputs1.data, 1)\n",
    "        total_train += 2*labels.size(0)\n",
    "        for i in range(labels.size(0)):\n",
    "            if(predicted[i] == labels[i]//10):\n",
    "                correct_train += 1\n",
    "            if(predicted1[i] == labels[i]%10):\n",
    "                correct_train += 1\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    average_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {average_train_loss:.4f} - Train Accuracy: {train_accuracy:.2f}%')\n",
    "    model.eval()\n",
    "    model1.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            labels1 = labels // 10\n",
    "            labels2 = labels % 10\n",
    "            image = images.clone()\n",
    "            image1 = images.clone()\n",
    "            left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "            image[:, :, :, (image.shape[3] // 2):] = left_half\n",
    "            right_half = images[:, :, :, images.shape[3] // 2 :]\n",
    "            image1[:, :, :, :(image1.shape[3] // 2)] = right_half\n",
    "            outputs = model(image)\n",
    "            outputs1 = model1(image1)\n",
    "            loss = criterion(outputs, labels1)\n",
    "            loss1 = criterion1(outputs1,labels2)\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, predicted1 = torch.max(outputs1.data, 1)\n",
    "            total_val += 2*labels.size(0)\n",
    "            for i in range(labels.size(0)):\n",
    "                if(predicted[i] == labels[i]//10):\n",
    "                    correct_val += 1\n",
    "                if(predicted1[i] == labels[i]%10):\n",
    "                    correct_val += 1\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    average_val_loss = total_val_loss / len(val_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Validation Loss: {average_val_loss:.4f} - Validation Accuracy: {val_accuracy:.2f}%')\n",
    "    model.eval()\n",
    "    model1.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            labels1 = labels // 10\n",
    "            labels2 = labels % 10\n",
    "            image = images.clone()\n",
    "            image1 = images.clone()\n",
    "            left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "            image[:, :, :, (image.shape[3] // 2):] = left_half\n",
    "            right_half = images[:, :, :, images.shape[3] // 2 :]\n",
    "            image1[:, :, :, :(image1.shape[3] // 2)] = right_half\n",
    "            outputs = model(image)\n",
    "            outputs1 = model1(image1)\n",
    "            loss = criterion(outputs, labels1)\n",
    "            loss1 = criterion1(outputs1,labels2)\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, predicted1 = torch.max(outputs1.data, 1)\n",
    "            total_val += 2*labels.size(0)\n",
    "            for i in range(labels.size(0)):\n",
    "                if(predicted[i] == labels[i]//10):\n",
    "                    correct_val += 1\n",
    "                if(predicted1[i] == labels[i]%10):\n",
    "                    correct_val += 1\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    average_val_loss = total_val_loss / len(test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Testing Loss: {average_val_loss:.4f} - Testing Accuracy: {val_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35fbdd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch 1/5 - Hidden layers: 1 - Hidden neurons: [128] - Train Accuracy: 21.31%\n",
      "Epoch 1/5 - Testing Loss: 2.1586 - Testing Accuracy: 14.15%\n",
      "Epoch 2/5 - Hidden layers: 1 - Hidden neurons: [128] - Train Accuracy: 29.21%\n",
      "Epoch 2/5 - Testing Loss: 2.1306 - Testing Accuracy: 18.86%\n",
      "Epoch 3/5 - Hidden layers: 1 - Hidden neurons: [128] - Train Accuracy: 31.58%\n",
      "Epoch 3/5 - Testing Loss: 2.0895 - Testing Accuracy: 20.61%\n",
      "Epoch 4/5 - Hidden layers: 1 - Hidden neurons: [128] - Train Accuracy: 32.52%\n",
      "Epoch 4/5 - Testing Loss: 2.0565 - Testing Accuracy: 23.17%\n",
      "Epoch 5/5 - Hidden layers: 1 - Hidden neurons: [128] - Train Accuracy: 33.28%\n",
      "Epoch 5/5 - Testing Loss: 2.0778 - Testing Accuracy: 19.66%\n",
      "0.001\n",
      "Epoch 1/5 - Hidden layers: 1 - Hidden neurons: [256] - Train Accuracy: 24.90%\n",
      "Epoch 1/5 - Testing Loss: 2.0725 - Testing Accuracy: 17.09%\n",
      "Epoch 2/5 - Hidden layers: 1 - Hidden neurons: [256] - Train Accuracy: 32.14%\n",
      "Epoch 2/5 - Testing Loss: 2.0318 - Testing Accuracy: 23.66%\n",
      "Epoch 3/5 - Hidden layers: 1 - Hidden neurons: [256] - Train Accuracy: 36.37%\n",
      "Epoch 3/5 - Testing Loss: 2.0058 - Testing Accuracy: 26.82%\n",
      "Epoch 4/5 - Hidden layers: 1 - Hidden neurons: [256] - Train Accuracy: 39.89%\n",
      "Epoch 4/5 - Testing Loss: 2.0033 - Testing Accuracy: 30.23%\n",
      "Epoch 5/5 - Hidden layers: 1 - Hidden neurons: [256] - Train Accuracy: 42.26%\n",
      "Epoch 5/5 - Testing Loss: 2.0387 - Testing Accuracy: 34.03%\n",
      "0.001\n",
      "Epoch 1/5 - Hidden layers: 2 - Hidden neurons: [128, 128] - Train Accuracy: 29.02%\n",
      "Epoch 1/5 - Testing Loss: 1.9914 - Testing Accuracy: 19.36%\n",
      "Epoch 2/5 - Hidden layers: 2 - Hidden neurons: [128, 128] - Train Accuracy: 37.24%\n",
      "Epoch 2/5 - Testing Loss: 1.8950 - Testing Accuracy: 26.02%\n",
      "Epoch 3/5 - Hidden layers: 2 - Hidden neurons: [128, 128] - Train Accuracy: 41.71%\n",
      "Epoch 3/5 - Testing Loss: 1.8039 - Testing Accuracy: 30.92%\n",
      "Epoch 4/5 - Hidden layers: 2 - Hidden neurons: [128, 128] - Train Accuracy: 48.22%\n",
      "Epoch 4/5 - Testing Loss: 1.6429 - Testing Accuracy: 38.14%\n",
      "Epoch 5/5 - Hidden layers: 2 - Hidden neurons: [128, 128] - Train Accuracy: 53.32%\n",
      "Epoch 5/5 - Testing Loss: 1.5376 - Testing Accuracy: 42.68%\n",
      "0.001\n",
      "Epoch 1/5 - Hidden layers: 2 - Hidden neurons: [256, 256] - Train Accuracy: 31.18%\n",
      "Epoch 1/5 - Testing Loss: 1.9314 - Testing Accuracy: 22.84%\n",
      "Epoch 2/5 - Hidden layers: 2 - Hidden neurons: [256, 256] - Train Accuracy: 43.78%\n",
      "Epoch 2/5 - Testing Loss: 1.7619 - Testing Accuracy: 33.72%\n",
      "Epoch 3/5 - Hidden layers: 2 - Hidden neurons: [256, 256] - Train Accuracy: 52.25%\n",
      "Epoch 3/5 - Testing Loss: 1.6185 - Testing Accuracy: 45.06%\n",
      "Epoch 4/5 - Hidden layers: 2 - Hidden neurons: [256, 256] - Train Accuracy: 58.93%\n",
      "Epoch 4/5 - Testing Loss: 1.3596 - Testing Accuracy: 55.39%\n",
      "Epoch 5/5 - Hidden layers: 2 - Hidden neurons: [256, 256] - Train Accuracy: 63.40%\n",
      "Epoch 5/5 - Testing Loss: 1.2762 - Testing Accuracy: 62.80%\n",
      "0.001\n",
      "Epoch 1/5 - Hidden layers: 3 - Hidden neurons: [128, 128, 128] - Train Accuracy: 29.15%\n",
      "Epoch 1/5 - Testing Loss: 1.9187 - Testing Accuracy: 19.99%\n",
      "Epoch 2/5 - Hidden layers: 3 - Hidden neurons: [128, 128, 128] - Train Accuracy: 40.27%\n",
      "Epoch 2/5 - Testing Loss: 1.7329 - Testing Accuracy: 29.04%\n",
      "Epoch 3/5 - Hidden layers: 3 - Hidden neurons: [128, 128, 128] - Train Accuracy: 49.11%\n",
      "Epoch 3/5 - Testing Loss: 1.4078 - Testing Accuracy: 39.62%\n",
      "Epoch 4/5 - Hidden layers: 3 - Hidden neurons: [128, 128, 128] - Train Accuracy: 55.67%\n",
      "Epoch 4/5 - Testing Loss: 1.2332 - Testing Accuracy: 50.92%\n",
      "Epoch 5/5 - Hidden layers: 3 - Hidden neurons: [128, 128, 128] - Train Accuracy: 61.21%\n",
      "Epoch 5/5 - Testing Loss: 1.0820 - Testing Accuracy: 59.24%\n",
      "0.001\n",
      "Epoch 1/5 - Hidden layers: 3 - Hidden neurons: [256, 256, 256] - Train Accuracy: 29.48%\n",
      "Epoch 1/5 - Testing Loss: 1.9253 - Testing Accuracy: 21.59%\n",
      "Epoch 2/5 - Hidden layers: 3 - Hidden neurons: [256, 256, 256] - Train Accuracy: 43.48%\n",
      "Epoch 2/5 - Testing Loss: 1.5646 - Testing Accuracy: 42.05%\n",
      "Epoch 3/5 - Hidden layers: 3 - Hidden neurons: [256, 256, 256] - Train Accuracy: 55.99%\n",
      "Epoch 3/5 - Testing Loss: 1.2817 - Testing Accuracy: 56.09%\n",
      "Epoch 4/5 - Hidden layers: 3 - Hidden neurons: [256, 256, 256] - Train Accuracy: 64.70%\n",
      "Epoch 4/5 - Testing Loss: 1.1181 - Testing Accuracy: 65.89%\n",
      "Epoch 5/5 - Hidden layers: 3 - Hidden neurons: [256, 256, 256] - Train Accuracy: 71.24%\n",
      "Epoch 5/5 - Testing Loss: 0.8539 - Testing Accuracy: 73.98%\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.001]\n",
    "hidden_layers = [1, 2,3]\n",
    "hidden_neurons = [128,256]\n",
    "for lrate in learning_rates:\n",
    "    for j in hidden_layers:\n",
    "        for k in hidden_neurons:\n",
    "            print(lrate)\n",
    "            input_size = 28 * 28\n",
    "            kk = [k]*j\n",
    "            model = SimpleMLP(input_size, num_classes=num_classes, hidden_layers = j, hidden_neurons = kk, dropout_rate = 0.5)\n",
    "            model1 = SimpleMLP(input_size, num_classes=num_classes, hidden_layers = j, hidden_neurons = kk, dropout_rate = 0.5)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lrate)\n",
    "            criterion1 = nn.CrossEntropyLoss()\n",
    "            optimizer1 = torch.optim.Adam(model1.parameters(), lr=lrate)\n",
    "            num_epochs = 5\n",
    "            for epoch in range(num_epochs):\n",
    "                model.train()\n",
    "                total_train_loss = 0\n",
    "                correct_train = 0\n",
    "                total_train = 0\n",
    "                cnt = 0\n",
    "                for images, labels in train_loader:\n",
    "                    labels1 = labels//10\n",
    "                    labels2 = labels%10\n",
    "                    # class_names = train_dataset.classes\n",
    "                    optimizer1.zero_grad()\n",
    "                    optimizer.zero_grad()\n",
    "                    image = images.clone()\n",
    "                    image1 = images.clone()\n",
    "                    left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "                    # print(left_half.shape)\n",
    "                    image[:, :, :, (image.shape[3] // 2):] = left_half\n",
    "                    right_half = images[:, :, :, images.shape[3] // 2 :]\n",
    "                    image1[:, :, :, :(image1.shape[3] // 2)] = right_half\n",
    "                    # print(images.shape)\n",
    "                    outputs = model(image)\n",
    "                    outputs1 = model1(image1)\n",
    "                    loss = criterion(outputs, labels1)\n",
    "                    loss1 = criterion1(outputs1,labels2)\n",
    "                    loss.backward()\n",
    "                    loss1.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer1.step()\n",
    "                    total_train_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    _, predicted1 = torch.max(outputs1.data, 1)\n",
    "                    total_train += 2*labels.size(0)\n",
    "                    for i in range(labels.size(0)):\n",
    "                        # cnt += 1\n",
    "                        # if(cnt == 10):\n",
    "                        #     print(predicted[i])\n",
    "                        #     print(predicted1[i])\n",
    "                        #     print(labels[i])\n",
    "                        #     cnt=0\n",
    "                        #     break\n",
    "                        if(predicted[i] == labels[i]//10):\n",
    "                            correct_train += 1\n",
    "                        if(predicted1[i] == labels[i]%10):\n",
    "                            correct_train += 1\n",
    "                    # cnt += 1\n",
    "                    # if(cnt == 10):\n",
    "                    #     break\n",
    "                train_accuracy = 100 * correct_train / total_train\n",
    "                average_train_loss = total_train_loss / len(train_loader)\n",
    "                print(f'Epoch {epoch+1}/{num_epochs} - Hidden layers: {j} - Hidden neurons: {kk} - Train Accuracy: {train_accuracy:.2f}%')\n",
    "                model.eval()\n",
    "                model1.eval()\n",
    "                total_val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "                cnt = 0\n",
    "                with torch.no_grad():\n",
    "                    for images, labels in test_loader:\n",
    "                        labels1 = labels // 10\n",
    "                        labels2 = labels % 10\n",
    "                        image = images.clone()\n",
    "                        image1 = images.clone()\n",
    "                        left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "                        image[:, :, :, (image.shape[3] // 2):] = left_half\n",
    "                        right_half = images[:, :, :, images.shape[3] // 2 :]\n",
    "                        image1[:, :, :, :(image1.shape[3] // 2)] = right_half\n",
    "                        outputs = model(image)\n",
    "                        outputs1 = model1(image1)\n",
    "                        loss = criterion(outputs, labels1)\n",
    "                        loss1 = criterion1(outputs1,labels2)\n",
    "                        total_val_loss += loss.item()\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        _, predicted1 = torch.max(outputs1.data, 1)\n",
    "                        total_val += 2*labels.size(0)\n",
    "                        for i in range(labels.size(0)):\n",
    "                            if(predicted[i] == labels[i]//10):\n",
    "                                correct_val += 1\n",
    "                            if(predicted1[i] == labels[i]%10):\n",
    "                                correct_val += 1\n",
    "                val_accuracy = 100 * correct_val / total_val\n",
    "                average_val_loss = total_val_loss / len(test_loader)\n",
    "                print(f'Epoch {epoch + 1}/{num_epochs} - Testing Loss: {average_val_loss:.4f} - Testing Accuracy: {val_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5569d85d",
   "metadata": {},
   "source": [
    "# 5.1.3 (Testing on regular MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "265b2c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 1.9254 - Train Accuracy: 29.83%\n",
      "Epoch 1/10 - Testing Loss: 1.8771 - Testing Accuracy: 12.67%\n",
      "Epoch 2/10 - Train Loss: 1.5908 - Train Accuracy: 43.52%\n",
      "Epoch 2/10 - Testing Loss: 3.8163 - Testing Accuracy: 7.15%\n",
      "Epoch 3/10 - Train Loss: 1.3089 - Train Accuracy: 56.22%\n",
      "Epoch 3/10 - Testing Loss: 4.8375 - Testing Accuracy: 6.52%\n",
      "Epoch 4/10 - Train Loss: 1.1054 - Train Accuracy: 65.05%\n",
      "Epoch 4/10 - Testing Loss: 4.9387 - Testing Accuracy: 6.93%\n",
      "Epoch 5/10 - Train Loss: 0.9295 - Train Accuracy: 71.27%\n",
      "Epoch 5/10 - Testing Loss: 4.9218 - Testing Accuracy: 7.92%\n",
      "Epoch 6/10 - Train Loss: 0.8090 - Train Accuracy: 74.94%\n",
      "Epoch 6/10 - Testing Loss: 5.6319 - Testing Accuracy: 6.92%\n",
      "Epoch 7/10 - Train Loss: 0.7375 - Train Accuracy: 77.50%\n",
      "Epoch 7/10 - Testing Loss: 6.1998 - Testing Accuracy: 7.36%\n",
      "Epoch 8/10 - Train Loss: 0.6779 - Train Accuracy: 79.31%\n",
      "Epoch 8/10 - Testing Loss: 6.8312 - Testing Accuracy: 7.67%\n",
      "Epoch 9/10 - Train Loss: 0.6392 - Train Accuracy: 80.62%\n",
      "Epoch 9/10 - Testing Loss: 6.0655 - Testing Accuracy: 8.05%\n",
      "Epoch 10/10 - Train Loss: 0.6103 - Train Accuracy: 81.67%\n",
      "Epoch 10/10 - Testing Loss: 6.2137 - Testing Accuracy: 7.04%\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "total_size = len(trainset)\n",
    "train_size = int(0.8 * total_size)\n",
    "validation_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - validation_size\n",
    "\n",
    "# Split the dataset\n",
    "gen = torch.Generator().manual_seed(42)\n",
    "train_set, validation_set, test_set = random_split(trainset, [train_size, validation_size, test_size],generator=gen)\n",
    "\n",
    "# Create data loaders for each set\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True,generator=gen)\n",
    "validationloader = torch.utils.data.DataLoader(validation_set, batch_size=64, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "input_size = 28 * 28\n",
    "num_classes = 10\n",
    "hidden_layers = 3\n",
    "hidden_neurons = [256,256,256]\n",
    "dropout_rate = 0.5\n",
    "\n",
    "\n",
    "model = SimpleMLP(input_size, num_classes, hidden_layers, hidden_neurons, dropout_rate)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model1 = SimpleMLP(input_size, num_classes, hidden_layers, hidden_neurons, dropout_rate)\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    cnt = 0\n",
    "    for images, labels in train_loader:\n",
    "        labels1 = labels//10\n",
    "        labels2 = labels%10\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        image = images.clone()\n",
    "        image1 = images.clone()\n",
    "        left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "        image[:, :, :, (image.shape[3] // 2):] = left_half\n",
    "        right_half = images[:, :, :, images.shape[3] // 2 :]\n",
    "        image1[:, :, :, :(image1.shape[3] // 2)] = right_half\n",
    "        outputs = model(image)\n",
    "        outputs1 = model1(image1)\n",
    "        loss = criterion(outputs, labels1)\n",
    "        loss1 = criterion1(outputs1,labels2)\n",
    "        loss.backward()\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "        optimizer1.step()\n",
    "        total_train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, predicted1 = torch.max(outputs1.data, 1)\n",
    "        total_train += 2*labels.size(0)\n",
    "        for i in range(labels.size(0)):\n",
    "            if(predicted[i] == labels[i]//10):\n",
    "                correct_train += 1\n",
    "            if(predicted1[i] == labels[i]%10):\n",
    "                correct_train += 1\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    average_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {average_train_loss:.4f} - Train Accuracy: {train_accuracy:.2f}%')\n",
    "    model.eval()\n",
    "    model1.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            labels1 = labels // 10\n",
    "            labels2 = labels % 10\n",
    "            image = images.clone()\n",
    "            image1 = images.clone()\n",
    "            left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "            image[:, :, :, (image.shape[3] // 2):] = left_half\n",
    "            right_half = images[:, :, :, images.shape[3] // 2 :]\n",
    "            image1[:, :, :, :(image1.shape[3] // 2)] = right_half\n",
    "            outputs = model(image)\n",
    "            outputs1 = model1(image1)\n",
    "            loss = criterion(outputs, labels1)\n",
    "            loss1 = criterion1(outputs1,labels2)\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, predicted1 = torch.max(outputs1.data, 1)\n",
    "            total_val += 2*labels.size(0)\n",
    "            for i in range(labels.size(0)):\n",
    "                if(predicted[i] == labels[i]//10):\n",
    "                    correct_val += 1\n",
    "                if(predicted1[i] == labels[i]%10):\n",
    "                    correct_val += 1\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    average_val_loss = total_val_loss / len(test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Testing Loss: {average_val_loss:.4f} - Testing Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

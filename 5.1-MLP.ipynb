{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94047bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79cdeb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '01', '04', '05', '06', '08', '09', '11', '12', '13', '14', '15', '16', '18', '19', '20', '21', '23', '24', '26', '28', '29', '30', '31', '33', '35', '37', '38', '41', '42', '43', '44', '45', '50', '51', '53', '54', '56', '59', '60', '62', '63', '65', '69', '70', '72', '74', '75', '76', '77', '79', '81', '82', '84', '85', '87', '88', '89', '90', '91', '94', '95', '97', '98']\n",
      "Dataset CustomImageFolder\n",
      "    Number of datapoints: 64000\n",
      "    Root location: double_mnist/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Grayscale(num_output_channels=1)\n",
      "               Resize(size=(28, 28), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5,), std=(0.5,))\n",
      "           )\n",
      "['03', '07', '10', '22', '27', '34', '39', '40', '48', '52', '58', '61', '64', '71', '93', '99']\n",
      "tensor([81, 77, 74, 12, 85, 41, 26, 45, 16, 82, 45, 56, 56, 89,  0, 30, 76, 21,\n",
      "        20, 21, 50, 62, 56, 63, 26, 65, 60, 65, 60, 35, 70, 95, 11, 87, 18, 42,\n",
      "        16, 97, 81, 60, 21, 65,  5, 54, 35, 43, 79, 15,  5, 91, 14, 28, 50, 15,\n",
      "        88, 37,  6, 75, 56, 65, 37, 62, 76, 33])\n",
      "tensor(3)\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  \n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_data_path = 'double_mnist/train'\n",
    "val_data_path = 'double_mnist/val'\n",
    "test_data_path = 'double_mnist/test'\n",
    "class CustomImageFolder(ImageFolder):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super(CustomImageFolder, self).__init__(root, transform=transform)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        folder_name = os.path.basename(os.path.dirname(path))\n",
    "        return sample, int(folder_name)  \n",
    "train_dataset = CustomImageFolder(train_data_path, transform=transform)\n",
    "val_dataset = CustomImageFolder(val_data_path, transform=transform)\n",
    "test_dataset = CustomImageFolder(test_data_path, transform=transform)\n",
    "print(train_dataset.classes)\n",
    "class_to_label = {str(i).zfill(2): i for i in range(100)}\n",
    "batch_size = 64\n",
    "print(train_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "class_names = val_dataset.classes\n",
    "\n",
    "print(class_names)\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print(labels)\n",
    "    break\n",
    "for images, labels in val_loader:\n",
    "    plt.imshow(images[0].permute(1, 2, 0))\n",
    "    print(labels[0])\n",
    "    print(labels)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2471806",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, hidden_layers, hidden_neurons, dropout_rate=0.5):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_size, hidden_neurons[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "        for i in range(1, hidden_layers):\n",
    "            layers.append(nn.Linear(hidden_neurons[i-1], hidden_neurons[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.hidden = nn.Sequential(*layers)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc_out = nn.Linear(hidden_neurons[-1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = self.hidden(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "input_size = 28 * 28\n",
    "num_classes = 10\n",
    "hidden_layers = 3\n",
    "hidden_neurons = [256,256,256]  \n",
    "dropout_rate = 0.5\n",
    "\n",
    "\n",
    "model = SimpleMLP(input_size, num_classes, hidden_layers, hidden_neurons, dropout_rate)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model1 = SimpleMLP(input_size, num_classes, hidden_layers, hidden_neurons, dropout_rate)\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c3909ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Train Loss: 1.9690 - Train Accuracy: 29.12%\n",
      "Epoch 1/25 - Validation Loss: 1.9367 - Validation Accuracy: 32.68%\n",
      "Epoch 1/25 - Testing Loss: 1.9647 - Testing Accuracy: 22.71%\n",
      "Epoch 2/25 - Train Loss: 1.7751 - Train Accuracy: 38.38%\n",
      "Epoch 2/25 - Validation Loss: 1.7664 - Validation Accuracy: 38.00%\n",
      "Epoch 2/25 - Testing Loss: 1.8324 - Testing Accuracy: 27.10%\n",
      "Epoch 3/25 - Train Loss: 1.6701 - Train Accuracy: 43.74%\n",
      "Epoch 3/25 - Validation Loss: 1.6841 - Validation Accuracy: 43.07%\n",
      "Epoch 3/25 - Testing Loss: 1.7891 - Testing Accuracy: 31.87%\n",
      "Epoch 4/25 - Train Loss: 1.5503 - Train Accuracy: 47.49%\n",
      "Epoch 4/25 - Validation Loss: 1.4802 - Validation Accuracy: 48.10%\n",
      "Epoch 4/25 - Testing Loss: 1.5961 - Testing Accuracy: 37.47%\n",
      "Epoch 5/25 - Train Loss: 1.4497 - Train Accuracy: 51.95%\n",
      "Epoch 5/25 - Validation Loss: 1.4572 - Validation Accuracy: 48.67%\n",
      "Epoch 5/25 - Testing Loss: 1.5138 - Testing Accuracy: 40.95%\n",
      "Epoch 6/25 - Train Loss: 1.3934 - Train Accuracy: 55.59%\n",
      "Epoch 6/25 - Validation Loss: 1.3352 - Validation Accuracy: 57.17%\n",
      "Epoch 6/25 - Testing Loss: 1.4182 - Testing Accuracy: 49.75%\n",
      "Epoch 7/25 - Train Loss: 1.3405 - Train Accuracy: 58.22%\n",
      "Epoch 7/25 - Validation Loss: 1.3019 - Validation Accuracy: 56.53%\n",
      "Epoch 7/25 - Testing Loss: 1.3486 - Testing Accuracy: 51.60%\n",
      "Epoch 8/25 - Train Loss: 1.3020 - Train Accuracy: 60.13%\n",
      "Epoch 8/25 - Validation Loss: 1.2345 - Validation Accuracy: 60.84%\n",
      "Epoch 8/25 - Testing Loss: 1.2719 - Testing Accuracy: 55.93%\n",
      "Epoch 9/25 - Train Loss: 1.2704 - Train Accuracy: 61.65%\n",
      "Epoch 9/25 - Validation Loss: 1.2182 - Validation Accuracy: 63.37%\n",
      "Epoch 9/25 - Testing Loss: 1.2385 - Testing Accuracy: 58.87%\n",
      "Epoch 10/25 - Train Loss: 1.2459 - Train Accuracy: 62.63%\n",
      "Epoch 10/25 - Validation Loss: 1.1688 - Validation Accuracy: 63.83%\n",
      "Epoch 10/25 - Testing Loss: 1.2808 - Testing Accuracy: 58.37%\n",
      "Epoch 11/25 - Train Loss: 1.2278 - Train Accuracy: 63.49%\n",
      "Epoch 11/25 - Validation Loss: 1.1690 - Validation Accuracy: 63.99%\n",
      "Epoch 11/25 - Testing Loss: 1.1831 - Testing Accuracy: 61.76%\n",
      "Epoch 12/25 - Train Loss: 1.2037 - Train Accuracy: 64.50%\n",
      "Epoch 12/25 - Validation Loss: 1.1448 - Validation Accuracy: 65.45%\n",
      "Epoch 12/25 - Testing Loss: 1.1624 - Testing Accuracy: 62.38%\n",
      "Epoch 13/25 - Train Loss: 1.1814 - Train Accuracy: 65.20%\n",
      "Epoch 13/25 - Validation Loss: 1.1259 - Validation Accuracy: 64.60%\n",
      "Epoch 13/25 - Testing Loss: 1.1871 - Testing Accuracy: 59.64%\n",
      "Epoch 14/25 - Train Loss: 1.1668 - Train Accuracy: 65.79%\n",
      "Epoch 14/25 - Validation Loss: 1.0945 - Validation Accuracy: 67.22%\n",
      "Epoch 14/25 - Testing Loss: 1.1082 - Testing Accuracy: 64.41%\n",
      "Epoch 15/25 - Train Loss: 1.1564 - Train Accuracy: 66.41%\n",
      "Epoch 15/25 - Validation Loss: 1.0843 - Validation Accuracy: 65.67%\n",
      "Epoch 15/25 - Testing Loss: 1.1682 - Testing Accuracy: 62.78%\n",
      "Epoch 16/25 - Train Loss: 1.1351 - Train Accuracy: 66.98%\n",
      "Epoch 16/25 - Validation Loss: 1.0534 - Validation Accuracy: 67.58%\n",
      "Epoch 16/25 - Testing Loss: 1.0984 - Testing Accuracy: 64.39%\n",
      "Epoch 17/25 - Train Loss: 1.1293 - Train Accuracy: 67.35%\n",
      "Epoch 17/25 - Validation Loss: 1.0347 - Validation Accuracy: 70.28%\n",
      "Epoch 17/25 - Testing Loss: 1.0495 - Testing Accuracy: 66.82%\n",
      "Epoch 18/25 - Train Loss: 1.1172 - Train Accuracy: 67.69%\n",
      "Epoch 18/25 - Validation Loss: 1.0600 - Validation Accuracy: 66.98%\n",
      "Epoch 18/25 - Testing Loss: 1.0854 - Testing Accuracy: 63.46%\n",
      "Epoch 19/25 - Train Loss: 1.1029 - Train Accuracy: 68.26%\n",
      "Epoch 19/25 - Validation Loss: 1.0046 - Validation Accuracy: 68.30%\n",
      "Epoch 19/25 - Testing Loss: 1.0852 - Testing Accuracy: 64.17%\n",
      "Epoch 20/25 - Train Loss: 1.0898 - Train Accuracy: 68.65%\n",
      "Epoch 20/25 - Validation Loss: 0.9762 - Validation Accuracy: 71.07%\n",
      "Epoch 20/25 - Testing Loss: 1.0061 - Testing Accuracy: 67.19%\n",
      "Epoch 21/25 - Train Loss: 1.0787 - Train Accuracy: 68.93%\n",
      "Epoch 21/25 - Validation Loss: 0.9533 - Validation Accuracy: 70.58%\n",
      "Epoch 21/25 - Testing Loss: 0.9742 - Testing Accuracy: 68.29%\n",
      "Epoch 22/25 - Train Loss: 1.0712 - Train Accuracy: 69.27%\n",
      "Epoch 22/25 - Validation Loss: 1.0268 - Validation Accuracy: 69.91%\n",
      "Epoch 22/25 - Testing Loss: 1.0326 - Testing Accuracy: 67.23%\n",
      "Epoch 23/25 - Train Loss: 1.0557 - Train Accuracy: 69.87%\n",
      "Epoch 23/25 - Validation Loss: 0.9559 - Validation Accuracy: 71.05%\n",
      "Epoch 23/25 - Testing Loss: 0.9949 - Testing Accuracy: 67.73%\n",
      "Epoch 24/25 - Train Loss: 1.0451 - Train Accuracy: 70.12%\n",
      "Epoch 24/25 - Validation Loss: 0.9200 - Validation Accuracy: 73.37%\n",
      "Epoch 24/25 - Testing Loss: 0.9508 - Testing Accuracy: 70.29%\n",
      "Epoch 25/25 - Train Loss: 1.0403 - Train Accuracy: 70.43%\n",
      "Epoch 25/25 - Validation Loss: 1.0144 - Validation Accuracy: 71.74%\n",
      "Epoch 25/25 - Testing Loss: 1.0434 - Testing Accuracy: 67.65%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    cnt = 0\n",
    "    for images, labels in train_loader:\n",
    "        labels1 = labels//10\n",
    "        labels2 = labels%10\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        image = images.clone()\n",
    "        image1 = images.clone()\n",
    "        left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "        image[:, :, :, (image.shape[3] // 2):] = left_half\n",
    "        right_half = images[:, :, :, images.shape[3] // 2 :]\n",
    "        image1[:, :, :, :(image1.shape[3] // 2)] = right_half\n",
    "        outputs = model(image)\n",
    "        outputs1 = model1(image1)\n",
    "        loss = criterion(outputs, labels1)\n",
    "        loss1 = criterion1(outputs1,labels2)\n",
    "        loss.backward()\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "        optimizer1.step()\n",
    "        total_train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, predicted1 = torch.max(outputs1.data, 1)\n",
    "        total_train += 2*labels.size(0)\n",
    "        for i in range(labels.size(0)):\n",
    "            if(predicted[i] == labels[i]//10):\n",
    "                correct_train += 1\n",
    "            if(predicted1[i] == labels[i]%10):\n",
    "                correct_train += 1\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    average_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {average_train_loss:.4f} - Train Accuracy: {train_accuracy:.2f}%')\n",
    "    model.eval()\n",
    "    model1.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            labels1 = labels // 10\n",
    "            labels2 = labels % 10\n",
    "            image = images.clone()\n",
    "            image1 = images.clone()\n",
    "            left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "            image[:, :, :, (image.shape[3] // 2):] = left_half\n",
    "            right_half = images[:, :, :, images.shape[3] // 2 :]\n",
    "            image1[:, :, :, :(image1.shape[3] // 2)] = right_half\n",
    "            outputs = model(image)\n",
    "            outputs1 = model1(image1)\n",
    "            loss = criterion(outputs, labels1)\n",
    "            loss1 = criterion1(outputs1,labels2)\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, predicted1 = torch.max(outputs1.data, 1)\n",
    "            total_val += 2*labels.size(0)\n",
    "            for i in range(labels.size(0)):\n",
    "                if(predicted[i] == labels[i]//10):\n",
    "                    correct_val += 1\n",
    "                if(predicted1[i] == labels[i]%10):\n",
    "                    correct_val += 1\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    average_val_loss = total_val_loss / len(val_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Validation Loss: {average_val_loss:.4f} - Validation Accuracy: {val_accuracy:.2f}%')\n",
    "    model.eval()\n",
    "    model1.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            labels1 = labels // 10\n",
    "            labels2 = labels % 10\n",
    "            image = images.clone()\n",
    "            image1 = images.clone()\n",
    "            left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "            image[:, :, :, (image.shape[3] // 2):] = left_half\n",
    "            right_half = images[:, :, :, images.shape[3] // 2 :]\n",
    "            image1[:, :, :, :(image1.shape[3] // 2)] = right_half\n",
    "            outputs = model(image)\n",
    "            outputs1 = model1(image1)\n",
    "            loss = criterion(outputs, labels1)\n",
    "            loss1 = criterion1(outputs1,labels2)\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, predicted1 = torch.max(outputs1.data, 1)\n",
    "            total_val += 2*labels.size(0)\n",
    "            for i in range(labels.size(0)):\n",
    "                if(predicted[i] == labels[i]//10):\n",
    "                    correct_val += 1\n",
    "                if(predicted1[i] == labels[i]%10):\n",
    "                    correct_val += 1\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    average_val_loss = total_val_loss / len(test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Testing Loss: {average_val_loss:.4f} - Testing Accuracy: {val_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35fbdd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlsamourya07\u001b[0m (\u001b[33mmourya\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 5brbpgfk\n",
      "Sweep URL: https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 70n1e0ee with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_neurons: 128\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntulsa/Sem5/SMAI/Assignment 3/wandb/run-20231022_162628-70n1e0ee</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/70n1e0ee' target=\"_blank\">silvery-sweep-1</a></strong> to <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/70n1e0ee' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/70n1e0ee</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Hidden layers: 1 - Hidden neurons: [128] - Train Accuracy: 22.07%\n",
      "Epoch 1/5 - Testing Loss: 2.1264 - Testing Accuracy: 14.06%\n",
      "Epoch 2/5 - Hidden layers: 1 - Hidden neurons: [128] - Train Accuracy: 30.03%\n",
      "Epoch 2/5 - Testing Loss: 2.0566 - Testing Accuracy: 18.88%\n",
      "Epoch 3/5 - Hidden layers: 1 - Hidden neurons: [128] - Train Accuracy: 32.26%\n",
      "Epoch 3/5 - Testing Loss: 2.0639 - Testing Accuracy: 20.36%\n",
      "Epoch 4/5 - Hidden layers: 1 - Hidden neurons: [128] - Train Accuracy: 33.61%\n",
      "Epoch 4/5 - Testing Loss: 2.0124 - Testing Accuracy: 23.99%\n",
      "Epoch 5/5 - Hidden layers: 1 - Hidden neurons: [128] - Train Accuracy: 34.78%\n",
      "Epoch 5/5 - Testing Loss: 2.0085 - Testing Accuracy: 23.76%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b4655d660948c39ffdb80d12f327d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>23.76</td></tr><tr><td>train_accuracy</td><td>34.77578</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silvery-sweep-1</strong> at: <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/70n1e0ee' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/70n1e0ee</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231022_162628-70n1e0ee/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 72i7pcpd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_neurons: 256\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntulsa/Sem5/SMAI/Assignment 3/wandb/run-20231022_162858-72i7pcpd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/72i7pcpd' target=\"_blank\">effortless-sweep-2</a></strong> to <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/72i7pcpd' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/72i7pcpd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Hidden layers: 1 - Hidden neurons: [256] - Train Accuracy: 23.95%\n",
      "Epoch 1/5 - Testing Loss: 2.0938 - Testing Accuracy: 14.97%\n",
      "Epoch 2/5 - Hidden layers: 1 - Hidden neurons: [256] - Train Accuracy: 32.16%\n",
      "Epoch 2/5 - Testing Loss: 2.0694 - Testing Accuracy: 20.61%\n",
      "Epoch 3/5 - Hidden layers: 1 - Hidden neurons: [256] - Train Accuracy: 33.64%\n",
      "Epoch 3/5 - Testing Loss: 2.0124 - Testing Accuracy: 24.20%\n",
      "Epoch 4/5 - Hidden layers: 1 - Hidden neurons: [256] - Train Accuracy: 35.17%\n",
      "Epoch 4/5 - Testing Loss: 2.0062 - Testing Accuracy: 22.78%\n",
      "Epoch 5/5 - Hidden layers: 1 - Hidden neurons: [256] - Train Accuracy: 36.51%\n",
      "Epoch 5/5 - Testing Loss: 1.9480 - Testing Accuracy: 26.88%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2539dd59284a4480814bdfc27c1f9274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>26.8775</td></tr><tr><td>train_accuracy</td><td>36.50781</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">effortless-sweep-2</strong> at: <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/72i7pcpd' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/72i7pcpd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231022_162858-72i7pcpd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5vrvx4az with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_neurons: 128\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb9adb3849445aebeb5a92f7feabd6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112518177772776, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntulsa/Sem5/SMAI/Assignment 3/wandb/run-20231022_163153-5vrvx4az</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/5vrvx4az' target=\"_blank\">twilight-sweep-3</a></strong> to <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/5vrvx4az' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/5vrvx4az</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Hidden layers: 2 - Hidden neurons: [128, 128] - Train Accuracy: 29.57%\n",
      "Epoch 1/5 - Testing Loss: 1.9540 - Testing Accuracy: 22.29%\n",
      "Epoch 2/5 - Hidden layers: 2 - Hidden neurons: [128, 128] - Train Accuracy: 37.98%\n",
      "Epoch 2/5 - Testing Loss: 1.8834 - Testing Accuracy: 27.20%\n",
      "Epoch 3/5 - Hidden layers: 2 - Hidden neurons: [128, 128] - Train Accuracy: 43.37%\n",
      "Epoch 3/5 - Testing Loss: 1.7159 - Testing Accuracy: 31.83%\n",
      "Epoch 4/5 - Hidden layers: 2 - Hidden neurons: [128, 128] - Train Accuracy: 47.94%\n",
      "Epoch 4/5 - Testing Loss: 1.5660 - Testing Accuracy: 37.70%\n",
      "Epoch 5/5 - Hidden layers: 2 - Hidden neurons: [128, 128] - Train Accuracy: 51.21%\n",
      "Epoch 5/5 - Testing Loss: 1.4172 - Testing Accuracy: 45.61%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>45.6125</td></tr><tr><td>train_accuracy</td><td>51.20859</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-sweep-3</strong> at: <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/5vrvx4az' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/5vrvx4az</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231022_163153-5vrvx4az/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0xr39ujz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_neurons: 256\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntulsa/Sem5/SMAI/Assignment 3/wandb/run-20231022_163434-0xr39ujz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/0xr39ujz' target=\"_blank\">pleasant-sweep-4</a></strong> to <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/0xr39ujz' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/0xr39ujz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Hidden layers: 2 - Hidden neurons: [256, 256] - Train Accuracy: 30.35%\n",
      "Epoch 1/5 - Testing Loss: 1.9696 - Testing Accuracy: 22.78%\n",
      "Epoch 2/5 - Hidden layers: 2 - Hidden neurons: [256, 256] - Train Accuracy: 42.38%\n",
      "Epoch 2/5 - Testing Loss: 1.6943 - Testing Accuracy: 35.81%\n",
      "Epoch 3/5 - Hidden layers: 2 - Hidden neurons: [256, 256] - Train Accuracy: 52.27%\n",
      "Epoch 3/5 - Testing Loss: 1.5583 - Testing Accuracy: 48.77%\n",
      "Epoch 4/5 - Hidden layers: 2 - Hidden neurons: [256, 256] - Train Accuracy: 58.58%\n",
      "Epoch 4/5 - Testing Loss: 1.5356 - Testing Accuracy: 55.20%\n",
      "Epoch 5/5 - Hidden layers: 2 - Hidden neurons: [256, 256] - Train Accuracy: 62.48%\n",
      "Epoch 5/5 - Testing Loss: 1.5594 - Testing Accuracy: 57.45%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc69ee1b2b2e4dfcbefecf5890dc9bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>57.4475</td></tr><tr><td>train_accuracy</td><td>62.47578</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pleasant-sweep-4</strong> at: <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/0xr39ujz' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/0xr39ujz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231022_163434-0xr39ujz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mb5fwo4f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_neurons: 128\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntulsa/Sem5/SMAI/Assignment 3/wandb/run-20231022_163729-mb5fwo4f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/mb5fwo4f' target=\"_blank\">stellar-sweep-5</a></strong> to <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/mb5fwo4f' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/mb5fwo4f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Hidden layers: 3 - Hidden neurons: [128, 128, 128] - Train Accuracy: 28.58%\n",
      "Epoch 1/5 - Testing Loss: 2.0627 - Testing Accuracy: 18.29%\n",
      "Epoch 2/5 - Hidden layers: 3 - Hidden neurons: [128, 128, 128] - Train Accuracy: 38.40%\n",
      "Epoch 2/5 - Testing Loss: 1.7686 - Testing Accuracy: 27.50%\n",
      "Epoch 3/5 - Hidden layers: 3 - Hidden neurons: [128, 128, 128] - Train Accuracy: 46.01%\n",
      "Epoch 3/5 - Testing Loss: 1.5318 - Testing Accuracy: 39.41%\n",
      "Epoch 4/5 - Hidden layers: 3 - Hidden neurons: [128, 128, 128] - Train Accuracy: 51.82%\n",
      "Epoch 4/5 - Testing Loss: 1.4508 - Testing Accuracy: 42.84%\n",
      "Epoch 5/5 - Hidden layers: 3 - Hidden neurons: [128, 128, 128] - Train Accuracy: 56.73%\n",
      "Epoch 5/5 - Testing Loss: 1.3627 - Testing Accuracy: 49.94%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfbd5a47bd04ea9b9d23231ed054828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>49.9425</td></tr><tr><td>train_accuracy</td><td>56.73359</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-sweep-5</strong> at: <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/mb5fwo4f' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/mb5fwo4f</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231022_163729-mb5fwo4f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9htyxcxc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_neurons: 256\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntulsa/Sem5/SMAI/Assignment 3/wandb/run-20231022_164030-9htyxcxc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/9htyxcxc' target=\"_blank\">autumn-sweep-6</a></strong> to <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/sweeps/5brbpgfk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/9htyxcxc' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/9htyxcxc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Hidden layers: 3 - Hidden neurons: [256, 256, 256] - Train Accuracy: 30.74%\n",
      "Epoch 1/5 - Testing Loss: 1.9725 - Testing Accuracy: 22.80%\n",
      "Epoch 2/5 - Hidden layers: 3 - Hidden neurons: [256, 256, 256] - Train Accuracy: 42.86%\n",
      "Epoch 2/5 - Testing Loss: 1.7036 - Testing Accuracy: 36.24%\n",
      "Epoch 3/5 - Hidden layers: 3 - Hidden neurons: [256, 256, 256] - Train Accuracy: 54.12%\n",
      "Epoch 3/5 - Testing Loss: 1.3097 - Testing Accuracy: 52.64%\n",
      "Epoch 4/5 - Hidden layers: 3 - Hidden neurons: [256, 256, 256] - Train Accuracy: 62.67%\n",
      "Epoch 4/5 - Testing Loss: 1.2856 - Testing Accuracy: 57.21%\n",
      "Epoch 5/5 - Hidden layers: 3 - Hidden neurons: [256, 256, 256] - Train Accuracy: 68.72%\n",
      "Epoch 5/5 - Testing Loss: 1.1196 - Testing Accuracy: 66.38%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435761a90c3f466f8d1365403f810caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>66.375</td></tr><tr><td>train_accuracy</td><td>68.71563</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">autumn-sweep-6</strong> at: <a href='https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/9htyxcxc' target=\"_blank\">https://wandb.ai/mourya/5.1-MLP%20Hyperparameter%20Tuning/runs/9htyxcxc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231022_164030-9htyxcxc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "# learning_rates = [0.001]\n",
    "# hidden_layers = [1, 2,3]\n",
    "# hidden_neurons = [128,256]\n",
    "wandb.login()\n",
    "sweep_config = {\n",
    "    \"name\": \"5.1-MLP Hyperparameter Tuning\",\n",
    "    \"method\": \"grid\",\n",
    "    \"parameters\": {\n",
    "        \"hidden_layers\": {\"values\": [1,2,3]},\n",
    "        \"hidden_neurons\": {\"values\": [128, 256]},\n",
    "    },\n",
    "    \"metric\": {\"goal\": \"maximize\", \"name\": \"test_accuracy\"},\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"5.1-MLP Hyperparameter Tuning\")\n",
    "\n",
    "def train():\n",
    "    wandb.init(project=\"5.1-MLP Hyperparameter Tuning\")\n",
    "    j = wandb.config.hidden_layers\n",
    "    k = wandb.config.hidden_neurons\n",
    "    kk = [k]*j\n",
    "    model = SimpleMLP(input_size, num_classes=num_classes, hidden_layers = j, hidden_neurons = kk, dropout_rate = 0.5)\n",
    "    model1 = SimpleMLP(input_size, num_classes=num_classes, hidden_layers = j, hidden_neurons = kk, dropout_rate = 0.5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion1 = nn.CrossEntropyLoss()\n",
    "    optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
    "    num_epochs = 5\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        cnt = 0\n",
    "        for images, labels in train_loader:\n",
    "            labels1 = labels//10\n",
    "            labels2 = labels%10\n",
    "            # class_names = train_dataset.classes\n",
    "            optimizer1.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "            image = images.clone()\n",
    "            image1 = images.clone()\n",
    "            left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "            # print(left_half.shape)\n",
    "            image[:, :, :, (image.shape[3] // 2):] = left_half\n",
    "            right_half = images[:, :, :, images.shape[3] // 2 :]\n",
    "            image1[:, :, :, :(image1.shape[3] // 2)] = right_half\n",
    "            # print(images.shape)\n",
    "            outputs = model(image)\n",
    "            outputs1 = model1(image1)\n",
    "            loss = criterion(outputs, labels1)\n",
    "            loss1 = criterion1(outputs1,labels2)\n",
    "            loss.backward()\n",
    "            loss1.backward()\n",
    "            optimizer.step()\n",
    "            optimizer1.step()\n",
    "            total_train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, predicted1 = torch.max(outputs1.data, 1)\n",
    "            total_train += 2*labels.size(0)\n",
    "            for i in range(labels.size(0)):\n",
    "                # cnt += 1\n",
    "                # if(cnt == 10):\n",
    "                #     print(predicted[i])\n",
    "                #     print(predicted1[i])\n",
    "                #     print(labels[i])\n",
    "                #     cnt=0\n",
    "                #     break\n",
    "                if(predicted[i] == labels[i]//10):\n",
    "                    correct_train += 1\n",
    "                if(predicted1[i] == labels[i]%10):\n",
    "                    correct_train += 1\n",
    "            # cnt += 1\n",
    "            # if(cnt == 10):\n",
    "            #     break\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        average_train_loss = total_train_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - Hidden layers: {j} - Hidden neurons: {kk} - Train Accuracy: {train_accuracy:.2f}%')\n",
    "        model.eval()\n",
    "        model1.eval()\n",
    "        total_val_loss = 0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        cnt = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                labels1 = labels // 10\n",
    "                labels2 = labels % 10\n",
    "                image = images.clone()\n",
    "                image1 = images.clone()\n",
    "                left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "                image[:, :, :, (image.shape[3] // 2):] = left_half\n",
    "                right_half = images[:, :, :, images.shape[3] // 2 :]\n",
    "                image1[:, :, :, :(image1.shape[3] // 2)] = right_half\n",
    "                outputs = model(image)\n",
    "                outputs1 = model1(image1)\n",
    "                loss = criterion(outputs, labels1)\n",
    "                loss1 = criterion1(outputs1,labels2)\n",
    "                total_val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                _, predicted1 = torch.max(outputs1.data, 1)\n",
    "                total_val += 2*labels.size(0)\n",
    "                for i in range(labels.size(0)):\n",
    "                    if(predicted[i] == labels[i]//10):\n",
    "                        correct_val += 1\n",
    "                    if(predicted1[i] == labels[i]%10):\n",
    "                        correct_val += 1\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "        average_val_loss = total_val_loss / len(test_loader)\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs} - Testing Loss: {average_val_loss:.4f} - Testing Accuracy: {val_accuracy:.2f}%')\n",
    "    wandb.log({\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"test_accuracy\": val_accuracy\n",
    "        })\n",
    "wandb.agent(sweep_id, function = train)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5569d85d",
   "metadata": {},
   "source": [
    "# 5.1.3 (Testing on regular MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "265b2c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 1.9254 - Train Accuracy: 29.83%\n",
      "Epoch 1/10 - Testing Loss: 1.8771 - Testing Accuracy: 12.67%\n",
      "Epoch 2/10 - Train Loss: 1.5908 - Train Accuracy: 43.52%\n",
      "Epoch 2/10 - Testing Loss: 3.8163 - Testing Accuracy: 7.15%\n",
      "Epoch 3/10 - Train Loss: 1.3089 - Train Accuracy: 56.22%\n",
      "Epoch 3/10 - Testing Loss: 4.8375 - Testing Accuracy: 6.52%\n",
      "Epoch 4/10 - Train Loss: 1.1054 - Train Accuracy: 65.05%\n",
      "Epoch 4/10 - Testing Loss: 4.9387 - Testing Accuracy: 6.93%\n",
      "Epoch 5/10 - Train Loss: 0.9295 - Train Accuracy: 71.27%\n",
      "Epoch 5/10 - Testing Loss: 4.9218 - Testing Accuracy: 7.92%\n",
      "Epoch 6/10 - Train Loss: 0.8090 - Train Accuracy: 74.94%\n",
      "Epoch 6/10 - Testing Loss: 5.6319 - Testing Accuracy: 6.92%\n",
      "Epoch 7/10 - Train Loss: 0.7375 - Train Accuracy: 77.50%\n",
      "Epoch 7/10 - Testing Loss: 6.1998 - Testing Accuracy: 7.36%\n",
      "Epoch 8/10 - Train Loss: 0.6779 - Train Accuracy: 79.31%\n",
      "Epoch 8/10 - Testing Loss: 6.8312 - Testing Accuracy: 7.67%\n",
      "Epoch 9/10 - Train Loss: 0.6392 - Train Accuracy: 80.62%\n",
      "Epoch 9/10 - Testing Loss: 6.0655 - Testing Accuracy: 8.05%\n",
      "Epoch 10/10 - Train Loss: 0.6103 - Train Accuracy: 81.67%\n",
      "Epoch 10/10 - Testing Loss: 6.2137 - Testing Accuracy: 7.04%\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "total_size = len(trainset)\n",
    "train_size = int(0.8 * total_size)\n",
    "validation_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - validation_size\n",
    "\n",
    "# Split the dataset\n",
    "gen = torch.Generator().manual_seed(42)\n",
    "train_set, validation_set, test_set = random_split(trainset, [train_size, validation_size, test_size],generator=gen)\n",
    "\n",
    "# Create data loaders for each set\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True,generator=gen)\n",
    "validationloader = torch.utils.data.DataLoader(validation_set, batch_size=64, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "input_size = 28 * 28\n",
    "num_classes = 10\n",
    "hidden_layers = 3\n",
    "hidden_neurons = [256,256,256]\n",
    "dropout_rate = 0.5\n",
    "\n",
    "\n",
    "model = SimpleMLP(input_size, num_classes, hidden_layers, hidden_neurons, dropout_rate)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model1 = SimpleMLP(input_size, num_classes, hidden_layers, hidden_neurons, dropout_rate)\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    cnt = 0\n",
    "    for images, labels in train_loader:\n",
    "        labels1 = labels//10\n",
    "        labels2 = labels%10\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        image = images.clone()\n",
    "        image1 = images.clone()\n",
    "        left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "        image[:, :, :, (image.shape[3] // 2):] = left_half\n",
    "        right_half = images[:, :, :, images.shape[3] // 2 :]\n",
    "        image1[:, :, :, :(image1.shape[3] // 2)] = right_half\n",
    "        outputs = model(image)\n",
    "        outputs1 = model1(image1)\n",
    "        loss = criterion(outputs, labels1)\n",
    "        loss1 = criterion1(outputs1,labels2)\n",
    "        loss.backward()\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "        optimizer1.step()\n",
    "        total_train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, predicted1 = torch.max(outputs1.data, 1)\n",
    "        total_train += 2*labels.size(0)\n",
    "        for i in range(labels.size(0)):\n",
    "            if(predicted[i] == labels[i]//10):\n",
    "                correct_train += 1\n",
    "            if(predicted1[i] == labels[i]%10):\n",
    "                correct_train += 1\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    average_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {average_train_loss:.4f} - Train Accuracy: {train_accuracy:.2f}%')\n",
    "    model.eval()\n",
    "    model1.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            labels1 = labels // 10\n",
    "            labels2 = labels % 10\n",
    "            image = images.clone()\n",
    "            image1 = images.clone()\n",
    "            left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "            image[:, :, :, (image.shape[3] // 2):] = left_half\n",
    "            right_half = images[:, :, :, images.shape[3] // 2 :]\n",
    "            image1[:, :, :, :(image1.shape[3] // 2)] = right_half\n",
    "            outputs = model(image)\n",
    "            outputs1 = model1(image1)\n",
    "            loss = criterion(outputs, labels1)\n",
    "            loss1 = criterion1(outputs1,labels2)\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, predicted1 = torch.max(outputs1.data, 1)\n",
    "            total_val += 2*labels.size(0)\n",
    "            for i in range(labels.size(0)):\n",
    "                if(predicted[i] == labels[i]//10):\n",
    "                    correct_val += 1\n",
    "                if(predicted1[i] == labels[i]%10):\n",
    "                    correct_val += 1\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    average_val_loss = total_val_loss / len(test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Testing Loss: {average_val_loss:.4f} - Testing Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

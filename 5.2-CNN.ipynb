{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4cb5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8dc059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_images', 'train_labels', 'test_images', 'test_labels']\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"permuted_mnist.npz\")\n",
    "permuted_x_train = data[\"train_images\"]\n",
    "y_train = data[\"train_labels\"]\n",
    "permuted_x_test = data[\"test_images\"]\n",
    "y_test = data[\"test_labels\"]\n",
    "\n",
    "print(data.files)\n",
    "print(permuted_x_test.shape)\n",
    "\n",
    "permuted_x_train, permuted_x_val, y_train, y_val = train_test_split(\n",
    "    permuted_x_train, y_train, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "permuted_x_train = torch.from_numpy(permuted_x_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "permuted_x_val = torch.from_numpy(permuted_x_val).float()\n",
    "y_val = torch.from_numpy(y_val).long()\n",
    "permuted_x_test = torch.from_numpy(permuted_x_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca1e2a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PermutedMNISTCNN(nn.Module):\n",
    "    def __init__(self, num_permutations, kernel_size=3, pool_size=2, stride=2, dropout_rate=0.5):\n",
    "        super(PermutedMNISTCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=kernel_size, padding=int((kernel_size - 1) / 2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=pool_size, stride=stride)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=kernel_size, padding=int((kernel_size - 1) / 2))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=pool_size, stride=stride)\n",
    "        var1 = int((28 - pool_size) / stride) + 1\n",
    "        self.dim = int((var1 - pool_size) / stride) + 1\n",
    "        self.fc1 = nn.Linear(64 * self.dim * self.dim, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(128, num_permutations)  # Output should be the number of permutations\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * self.dim * self.dim)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b946233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Accuracy: 81.26%\n",
      "Epoch 1/10, Validation Accuracy: 92.10%\n",
      "Epoch 1/10, Testing Accuracy: 92.23%\n",
      "Epoch 2/10, Training Accuracy: 89.62%\n",
      "Epoch 2/10, Validation Accuracy: 93.25%\n",
      "Epoch 2/10, Testing Accuracy: 93.21%\n",
      "Epoch 3/10, Training Accuracy: 91.24%\n",
      "Epoch 3/10, Validation Accuracy: 93.75%\n",
      "Epoch 3/10, Testing Accuracy: 93.58%\n",
      "Epoch 4/10, Training Accuracy: 92.28%\n",
      "Epoch 4/10, Validation Accuracy: 94.45%\n",
      "Epoch 4/10, Testing Accuracy: 94.44%\n",
      "Epoch 5/10, Training Accuracy: 92.74%\n",
      "Epoch 5/10, Validation Accuracy: 94.78%\n",
      "Epoch 5/10, Testing Accuracy: 94.86%\n",
      "Epoch 6/10, Training Accuracy: 93.43%\n",
      "Epoch 6/10, Validation Accuracy: 95.10%\n",
      "Epoch 6/10, Testing Accuracy: 95.25%\n",
      "Epoch 7/10, Training Accuracy: 93.92%\n",
      "Epoch 7/10, Validation Accuracy: 95.53%\n",
      "Epoch 7/10, Testing Accuracy: 95.32%\n",
      "Epoch 8/10, Training Accuracy: 94.33%\n",
      "Epoch 8/10, Validation Accuracy: 95.70%\n",
      "Epoch 8/10, Testing Accuracy: 95.53%\n",
      "Epoch 9/10, Training Accuracy: 94.61%\n",
      "Epoch 9/10, Validation Accuracy: 95.18%\n",
      "Epoch 9/10, Testing Accuracy: 95.09%\n",
      "Epoch 10/10, Training Accuracy: 94.82%\n",
      "Epoch 10/10, Validation Accuracy: 95.40%\n",
      "Epoch 10/10, Testing Accuracy: 95.40%\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "num_permutations = 10  # Number of output classes\n",
    "model = PermutedMNISTCNN(num_permutations)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(permuted_x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = TensorDataset(permuted_x_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataset = TensorDataset(permuted_x_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.unsqueeze(1))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Accuracy: {accuracy:.2f}%\")\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs.unsqueeze(1))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs.unsqueeze(1))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Testing Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
